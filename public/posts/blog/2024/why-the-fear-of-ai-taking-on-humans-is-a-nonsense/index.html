<!doctype html>







































<html
  class="not-ready lg:text-base"
  style="--bg: #faf8f1"
  lang="en-us"
>
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no"
  />

  
  <title>Why the Fear of AI Taking on Humans s a Nonsense - Alexander Deplov – Senior Product Designer Blog</title>

  
  <meta name="theme-color" />

  
  
  
  
  <meta name="description" content="Lately you may hear a lot of talk about AI going wild and deciding to destroy humans and how dangerous that can be. This is such nonsense, and here is why.
First of all, AI must raise a question about humans. Only then should it make a decision to do something with it. From what we currently have, our AI systems have never asked a question. With a current state of technology it just runs a piece of code we ask to be loaded into a computer memory, chunk by chunk, and performs an output according to it." />
  <meta name="author" content="Alexander Deplov" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://alexdeplov.github.io/main.min.css" />

  
  
  
  
  
  <link rel="preload" as="image" href="https://alexdeplov.github.io/theme.svg" />

  
  
  
  
  <link rel="preload" as="image" href="https://gravatar.com/avatar/7a371a2fef36b02d83ee5e65f9a7721d?size=256&amp;cache=1718741543588" />
  
  

  
  
  <link rel="preload" as="image" href="https://alexdeplov.github.io/mastodon.svg" />
  
  <link rel="preload" as="image" href="https://alexdeplov.github.io/rss.svg" />
  
  

  
  
  <script
    defer
    src="https://alexdeplov.github.io/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
  
  
  
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css"
  integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI"
  crossorigin="anonymous"
/>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js"
  integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t"
  crossorigin="anonymous"
></script>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js"
  integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
  crossorigin="anonymous"
></script>


<script>
  document.addEventListener('DOMContentLoaded', () =>
    renderMathInElement(document.body, {
      
      
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '$', right: '$', display: false },
      ],
      
      throwOnError: false,
    }),
  );
</script>

  
  
  

  
  <link rel="icon" href="https://alexdeplov.github.io/favicon.ico" />
  <link rel="apple-touch-icon" href="https://alexdeplov.github.io/apple-touch-icon.png" />

  
  <meta name="generator" content="Hugo 0.127.0">

  
  
  
  
  


  
  
  <meta itemprop="name" content="Why the Fear of AI Taking on Humans s a Nonsense">
  <meta itemprop="description" content="Lately you may hear a lot of talk about AI going wild and deciding to destroy humans and how dangerous that can be. This is such nonsense, and here is why.
First of all, AI must raise a question about humans. Only then should it make a decision to do something with it. From what we currently have, our AI systems have never asked a question. With a current state of technology it just runs a piece of code we ask to be loaded into a computer memory, chunk by chunk, and performs an output according to it.">
  <meta itemprop="datePublished" content="2024-03-23T20:05:56+02:00">
  <meta itemprop="dateModified" content="2024-03-23T20:05:56+02:00">
  <meta itemprop="wordCount" content="213">
  
  <meta property="og:url" content="https://alexdeplov.github.io/posts/blog/2024/why-the-fear-of-ai-taking-on-humans-is-a-nonsense/">
  <meta property="og:site_name" content="Alexander Deplov – Senior Product Designer Blog">
  <meta property="og:title" content="Why the Fear of AI Taking on Humans s a Nonsense">
  <meta property="og:description" content="Lately you may hear a lot of talk about AI going wild and deciding to destroy humans and how dangerous that can be. This is such nonsense, and here is why.
First of all, AI must raise a question about humans. Only then should it make a decision to do something with it. From what we currently have, our AI systems have never asked a question. With a current state of technology it just runs a piece of code we ask to be loaded into a computer memory, chunk by chunk, and performs an output according to it.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-23T20:05:56+02:00">
    <meta property="article:modified_time" content="2024-03-23T20:05:56+02:00">

  
  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Why the Fear of AI Taking on Humans s a Nonsense">
  <meta name="twitter:description" content="Lately you may hear a lot of talk about AI going wild and deciding to destroy humans and how dangerous that can be. This is such nonsense, and here is why.
First of all, AI must raise a question about humans. Only then should it make a decision to do something with it. From what we currently have, our AI systems have never asked a question. With a current state of technology it just runs a piece of code we ask to be loaded into a computer memory, chunk by chunk, and performs an output according to it.">

  
  
  
  <link rel="canonical" href="https://alexdeplov.github.io/posts/blog/2024/why-the-fear-of-ai-taking-on-humans-is-a-nonsense/" />
  
  
</head>

  <body class="text-black duration-200 ease-out dark:text-white">
    <header class="mx-auto flex h-[4.5rem] max-w-3xl px-8 lg:justify-center">
  

  <div class="relative z-50 mr-auto flex items-center">
    <a
      class="websiteName -translate-x-[1px] -translate-y-[1px] text-1xl font-semibold"
      href="https://alexdeplov.github.io/"
      >Alexander Deplov – Senior Product Designer Blog</a
    >
    <div
      class="btn-dark text-[0] ml-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.svg)_left_center/cover_no-repeat] dark:invert dark:[background-position:right]"
      role="button"
      aria-label="Dark"
    ></div>
  </div>

  <div
    class="btn-menu relative z-50 -mr-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"
    role="button"
    aria-label="Menu"
  ></div>

  

  <script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = '#faf8f1'.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>

  <div
    class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"
  >
    
    

    
    <nav
      class="mt-12 flex justify-center space-x-10 dark:invert lg:ml-12 lg:mt-0 lg:items-center lg:space-x-6"
    >
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./mastodon.svg)"
        href="https://mastodon.social/@alex_deplov"
        target="_blank"
        rel="me"
      >
        mastodon
      </a>
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./rss.svg)"
        href="https://alexdeplov.github.io/index.xml"
        target="_blank"
        rel="alternate"
      >
        rss
      </a>
      
    </nav>
    
  </div>
</header>

    <main
      class="prose prose-neutral relative mx-auto min-h-[calc(100%-9rem)] max-w-3xl px-8 pb-16 pt-12 dark:prose-invert"
    >
      

<article>
  <header class="mb-16">
  

    <h1 class="mb-2">Why the Fear of AI Taking on Humans s a Nonsense</h1> 

    
    <div class="text-sm antialiased opacity-60">
      
      <time>Mar 23, 2024</time>
      
      
      
      
      <span class="mx-1">&middot;</span>
      <span>Alexander Deplov</span>
      
    </div>
    
  </header>

  <section><p>Lately you may hear a lot of talk about AI going wild and deciding to destroy humans and how dangerous that can be. This is such nonsense, and here is why.</p>
<ul>
<li>First of all, AI must <strong>raise a question</strong> about humans. Only then should it make a <strong>decision</strong> to do something with it.</li>
<li>From what we currently have, our AI systems have never asked a question. With a current state of technology it just runs a piece of code we ask to be loaded into a computer memory, chunk by chunk, and performs an output according to it.</li>
<li>Second, we know animals that can &ldquo;talk&rdquo;. Like parrots or Koko the gorilla. She can interact with humans. But even these animals have never asked a question. They answer/react to our questions only when asked, like in the case of a Koko or when you ask your dog to go outside and it gets excited.</li>
</ul>
<p>Every time I hear that AI can harm a human, I wonder if AI is already capable of:</p>
<ul>
<li>Deviate from output and ask a question without direct input to do so, by its own &ldquo;will&rdquo;, bypassing blocks of code loaded into a memory.</li>
</ul>
<p>Without it, I don&rsquo;t see how it can harm anyone if a question can never be asked.</p>
</section>

  
  

  
  

  
  

  
  

  


  
</article>


      
    </main>

    <footer
  class="opaco mx-auto flex h-[4.5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"
>
  <div class="mr-auto">
    &copy; 2024
    <a class="link" href="https://alexdeplov.github.io/">Alexander Deplov – Senior Product Designer Blog</a>
  </div>
  <a
    class="link"
    href="mailto:dep_social@outlook.de"
    rel="noopener"
    target="_blank"
    >✎ Reply via Email</a
  >
</footer>


    // Privacy-first tiny analytics
     <script src="https://tinylytics.app/embed/shJAYGtxXyRhWUeDDHzy.js" defer></script> 
  </body>
</html>
