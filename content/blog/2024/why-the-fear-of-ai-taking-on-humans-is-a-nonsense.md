+++
title = 'Why the Fear of AI Taking on Humans s a Nonsense'
date = 2024-03-23T20:05:56+02:00
aliases = ["/posts/blog/2024/why-the-fear-of-ai-taking-on-humans-is-a-nonsense/"]
draft = false
featured = false
author = "Alexander Deplov"
+++

Lately you may hear a lot of talk about AI going wild and deciding to destroy humans and how dangerous that can be. This is such nonsense, and here is why. 

* First of all, AI must **raise a question** about humans. Only then should it make a **decision** to do something with it. 
* From what we currently have, our AI systems have never asked a question. With a current state of technology it just runs a piece of code we ask to be loaded into a computer memory, chunk by chunk, and performs an output according to it. 
* Second, we know animals that can "talk". Like parrots or Koko the gorilla. She can interact with humans. But even these animals have never asked a question. They answer/react to our questions only when asked, like in the case of a Koko or when you ask your dog to go outside and it gets excited. 

Every time I hear that AI can harm a human, I wonder if AI is already capable of:
* Deviate from output and ask a question without direct input to do so, by its own "will", bypassing blocks of code loaded into a memory.

Without it, I don't see how it can harm anyone if a question can never be asked.